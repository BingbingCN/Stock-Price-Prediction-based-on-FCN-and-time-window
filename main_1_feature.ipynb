{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Price', 'Open', 'High', 'Low', 'Vol.', 'Change %'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Data    Price     Open     High      Low\n0    11/01/2022  2969.20  2899.50  2969.20  2896.76\n1    11/02/2022  3003.37  2960.65  3019.05  2954.95\n2    11/03/2022  2997.81  2981.20  3003.72  2977.72\n3    11/04/2022  3070.80  2997.00  3081.59  2997.00\n4    11/07/2022  3077.82  3062.86  3088.19  3054.46\n..          ...      ...      ...      ...      ...\n242  10/31/2023  3018.77  3019.65  3023.00  3006.61\n243  11/01/2023  3023.08  3038.18  3038.33  3013.93\n244  11/02/2023  3009.41  3028.66  3038.64  3009.12\n245  11/03/2023  3030.80  3012.47  3040.98  3012.47\n246  11/06/2023  3058.41  3047.13  3058.99  3037.69\n\n[247 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Price</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11/01/2022</td>\n      <td>2969.20</td>\n      <td>2899.50</td>\n      <td>2969.20</td>\n      <td>2896.76</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11/02/2022</td>\n      <td>3003.37</td>\n      <td>2960.65</td>\n      <td>3019.05</td>\n      <td>2954.95</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11/03/2022</td>\n      <td>2997.81</td>\n      <td>2981.20</td>\n      <td>3003.72</td>\n      <td>2977.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11/04/2022</td>\n      <td>3070.80</td>\n      <td>2997.00</td>\n      <td>3081.59</td>\n      <td>2997.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11/07/2022</td>\n      <td>3077.82</td>\n      <td>3062.86</td>\n      <td>3088.19</td>\n      <td>3054.46</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>10/31/2023</td>\n      <td>3018.77</td>\n      <td>3019.65</td>\n      <td>3023.00</td>\n      <td>3006.61</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>11/01/2023</td>\n      <td>3023.08</td>\n      <td>3038.18</td>\n      <td>3038.33</td>\n      <td>3013.93</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>11/02/2023</td>\n      <td>3009.41</td>\n      <td>3028.66</td>\n      <td>3038.64</td>\n      <td>3009.12</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>11/03/2023</td>\n      <td>3030.80</td>\n      <td>3012.47</td>\n      <td>3040.98</td>\n      <td>3012.47</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>11/06/2023</td>\n      <td>3058.41</td>\n      <td>3047.13</td>\n      <td>3058.99</td>\n      <td>3037.69</td>\n    </tr>\n  </tbody>\n</table>\n<p>247 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df1=pd.read_csv('./data/Shanghai Composite Historical Data.csv')\n",
    "print(df1.columns)\n",
    "df1=pd.DataFrame({\n",
    "    'Data':df1.Date.values[::-1],\n",
    "    'Price':[float(i.replace(',','')) for i in df1['Price'].values][::-1],\n",
    "    'Open':[float(i.replace(',','')) for i in df1['Open'].values][::-1],\n",
    "    'High':[float(i.replace(',','')) for i in df1['High'].values][::-1],\n",
    "    'Low':[float(i.replace(',','')) for i in df1['Low'].values][::-1]\n",
    "                  })\n",
    "df1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:18:21.546231Z",
     "end_time": "2023-11-07T11:18:26.220964Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247,)\n",
      "[0.06563385 0.14061574 0.128415   0.28858265 0.30398718 0.27473613\n",
      " 0.23892388 0.21250357 0.32476794 0.31623181 0.42744289 0.39650216\n",
      " 0.38651774 0.34660201] [0.31983059 0.32838867 0.34587786 0.32920059 0.35636699 0.30558908\n",
      " 0.46182879]\n",
      "226 226\n"
     ]
    }
   ],
   "source": [
    "#Params\n",
    "time_window = 14\n",
    "pred_window=7\n",
    "\n",
    "BATCH_SIZE=16\n",
    "nums_layer=1\n",
    "lr=5e-4\n",
    "test_size=0.2\n",
    "N_epoch=100\n",
    "device = torch.device('mps')\n",
    "\n",
    "Price_data2=df1['Price'].values.reshape(-1,1)\n",
    "\n",
    "scaler1=MinMaxScaler()\n",
    "Price_data=scaler1.fit_transform(Price_data2).reshape(-1)\n",
    "print(Price_data.shape)\n",
    "\n",
    "data_his=[]\n",
    "data_pred=[]\n",
    "for i in range(len(Price_data)-time_window-pred_window):\n",
    "    data_his.append(np.array(Price_data[i:i+time_window]))\n",
    "    data_pred.append(np.array(Price_data[i+time_window:i+time_window+pred_window]))\n",
    "\n",
    "print(data_his[0],data_pred[0])\n",
    "print(len(data_his),len(data_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:18:26.220369Z",
     "end_time": "2023-11-07T11:18:26.222312Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 14) (226, 7)\n",
      "(181, 14) (181, 7) (45, 14) (45, 7)\n",
      "torch.Size([16, 14])\n",
      "torch.Size([16, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/65/s4c34gg17dgbvj0pj8g_hvmw0000gn/T/ipykernel_9336/682025618.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1678454852765/work/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  label_value=torch.FloatTensor([self.label[index]])\n"
     ]
    }
   ],
   "source": [
    "data_his=np.array(data_his)\n",
    "data_pred=np.array(data_pred)\n",
    "\n",
    "\n",
    "\n",
    "print(data_his.shape,data_pred.shape)\n",
    "\n",
    "Train_x,Train_y=data_his[:-int(test_size*len(data_his))],data_pred[:-int(test_size*len(data_his))]\n",
    "Test_x,Test_y=data_his[-int(test_size*len(data_his)):],data_pred[-int(test_size*len(data_his)):]\n",
    "print(Train_x.shape,Train_y.shape,Test_x.shape,Test_y.shape)\n",
    "\n",
    "class TimeDataset(Dataset):\n",
    "    def __init__(self,df_x,df_y):\n",
    "        self.data=df_x\n",
    "        self.label=df_y\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,index):\n",
    "        data_value=torch.FloatTensor(self.data[index,:])\n",
    "        label_value=torch.FloatTensor([self.label[index]])\n",
    "        return data_value,label_value.view(-1)\n",
    "\n",
    "train_dataset=TimeDataset(df_x=Train_x,df_y=Train_y)\n",
    "valid_dataset=TimeDataset(df_x=Test_x,df_y=Test_y)\n",
    "train_iterator=DataLoader(train_dataset,batch_size=BATCH_SIZE)\n",
    "valid_iterator=DataLoader(valid_dataset,batch_size=BATCH_SIZE)\n",
    "#test\n",
    "for (data,label) in train_iterator:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:18:26.223123Z",
     "end_time": "2023-11-07T11:18:26.228037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self,InputDim=14,OutputDim=7,nums_layer=6):\n",
    "        super().__init__()\n",
    "        layers=[]\n",
    "        for i in range(nums_layer):\n",
    "            layers+=[nn.Linear(4096,4096),\n",
    "                     nn.LeakyReLU(),\n",
    "                     nn.Linear(4096,4096)\n",
    "                     ]\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Linear(InputDim, 4096),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.layer2=nn.Sequential(*layers)\n",
    "        self.layer3=nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4096,64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32,out_features=OutputDim),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self,data):\n",
    "        x=self.layer1(data)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        return x\n",
    "\n",
    "def train(model, iterator, optimizer, criterion,device='cpu'):\n",
    "    epoch_loss = 0\n",
    "    model=model.to(device)\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        batch[0]=batch[0].to(device)\n",
    "        batch[1]=batch[1].to(device)\n",
    "        criterion=criterion.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch[0])\n",
    "\n",
    "        loss = criterion(predictions, batch[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator,criterion,device='cpu'):\n",
    "    epoch_loss = 0\n",
    "    model=model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            batch[0]=batch[0].to(device)\n",
    "            batch[1]=batch[1].to(device)\n",
    "            criterion=criterion.to(device)\n",
    "            predictions = model(batch[0])\n",
    "            loss = criterion(predictions, batch[1])\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "lossfunction=nn.MSELoss()\n",
    "fc_model=FCN(InputDim=time_window,OutputDim=pred_window,nums_layer=nums_layer)\n",
    "# fc_model=FullyConnectedModel()\n",
    "optimizer=torch.optim.Adam(fc_model.parameters(),lr=lr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:18:26.228728Z",
     "end_time": "2023-11-07T11:18:26.341420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:28<00:00,  3.49it/s, Training Loss:0.0092 Valid Loss:0.0247]    \n"
     ]
    }
   ],
   "source": [
    "train_loss_list=[]\n",
    "valid_loss_list=[]\n",
    "\n",
    "par=tqdm(range(N_epoch))\n",
    "\n",
    "for i in par:\n",
    "    train_loss=train(model=fc_model,iterator=train_iterator,criterion=lossfunction,optimizer=optimizer,device=device)\n",
    "    valid_loss=evaluate(model=fc_model,iterator=valid_iterator,criterion=lossfunction,device=device)\n",
    "    # print(\"Epoch:{}\".format(i+1))\n",
    "    # print(\"Training Loss:{:.4f}\".format(train_loss),\"Valid Loss:{:.4f}\".format(valid_loss))\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    if i ==0:\n",
    "        best_valid_loss=valid_loss\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        # print('Save Model..')\n",
    "        par.set_description_str(\"Epoch:{}\".format(i+1)+' Save!')\n",
    "        torch.save(fc_model.state_dict(), './result/fc_model.pt')\n",
    "    else:\n",
    "        par.set_description_str(\"Epoch:{}\".format(i+1))\n",
    "\n",
    "    par.set_postfix_str(\"Training Loss:{:.4f}\".format(train_loss)+\" Valid Loss:{:.4f}\".format(valid_loss))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:18:26.338207Z",
     "end_time": "2023-11-07T11:18:55.048835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "fc_model.load_state_dict(torch.load('./result/fc_model.pt',map_location='cpu'))\n",
    "fc_model.to('cpu')\n",
    "train_iterator=DataLoader(train_dataset,batch_size=1)\n",
    "valid_iterator=DataLoader(valid_dataset,batch_size=1)\n",
    "list1=[]\n",
    "list2=[]\n",
    "real_y_1=[]\n",
    "real_y_2=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in train_iterator:\n",
    "        data=batch[0].to('cpu')\n",
    "        pre1=fc_model(data)[0][0]\n",
    "        list1.append(pre1)\n",
    "        real_y_1.append(batch[1].to('cpu')[0][0])\n",
    "\n",
    "    for batch in valid_iterator:\n",
    "         data=batch[0].to('cpu')\n",
    "         pre2=fc_model(data)[0][0]\n",
    "         list2.append(pre2)\n",
    "         real_y_2.append(batch[1].to('cpu')[0][0])\n",
    "\n",
    "list2=np.array([i.detach().numpy() for i in list2]).reshape(-1)\n",
    "list1=np.array([i.detach().numpy() for i in list1]).reshape(-1)\n",
    "real_y_1=np.array([i.detach().numpy() for i in real_y_1]).reshape(-1)\n",
    "real_y_2=np.array([i.detach().numpy() for i in real_y_2]).reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:18:55.050962Z",
     "end_time": "2023-11-07T11:18:56.201443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.20073573, 0.22735418, 0.23614548, 0.27058274, 0.292525  ,\n       0.30139175, 0.2806997 , 0.37731406, 0.43720466, 0.47344908,\n       0.44276297, 0.53538203, 0.5524705 , 0.5518103 , 0.540039  ,\n       0.51114863, 0.46343336, 0.41651723, 0.42311463, 0.3845584 ,\n       0.43030757, 0.31503358, 0.23915894, 0.20136927, 0.21563734,\n       0.2096029 , 0.23838927, 0.27731213, 0.2771646 , 0.26892385,\n       0.28525093, 0.3402821 , 0.37232515, 0.43766424, 0.460317  ,\n       0.49981484, 0.49416444, 0.48637846, 0.47187385, 0.52588123,\n       0.60910606, 0.6262388 , 0.6195865 , 0.6252323 , 0.67470527,\n       0.69827026, 0.6832399 , 0.7030019 , 0.70646167, 0.6761176 ,\n       0.61774945, 0.6297851 , 0.6419134 , 0.74372464, 0.7448019 ,\n       0.7837457 , 0.8085242 , 0.8003165 , 0.75365394, 0.70863336,\n       0.823173  , 0.87412345, 0.8426552 , 0.79105437, 0.752063  ,\n       0.7259906 , 0.81977725, 0.88741165, 0.8966512 , 0.8908686 ,\n       0.8594901 , 0.79734325, 0.7967921 , 0.8521381 , 0.7698147 ,\n       0.79105633, 0.7399111 , 0.73442435, 0.6382176 , 0.6906796 ,\n       0.6704621 , 0.72277665, 0.76618904, 0.8137447 , 0.77845526,\n       0.75095785, 0.74535656, 0.7263815 , 0.78702277, 0.80923   ,\n       0.8413849 , 0.838064  , 0.8458445 , 0.8587231 , 0.86220735,\n       0.8668589 , 0.88833994, 0.8683721 , 0.8737902 , 0.92926264,\n       0.9424753 , 0.9238669 , 0.9237558 , 0.8548125 , 0.82137626,\n       0.7974214 , 0.80885804, 0.8132292 , 0.8668236 , 0.8977003 ,\n       0.8361632 , 0.88761973, 0.8441174 , 0.8232222 , 0.83788866,\n       0.8128389 , 0.83317   , 0.7900118 , 0.75614446, 0.7430964 ,\n       0.7502536 , 0.78302526, 0.71770996, 0.626955  , 0.61733216,\n       0.65381986, 0.66624326, 0.66636944, 0.58352184, 0.55720216,\n       0.5940858 , 0.6229152 , 0.5969615 , 0.6000435 , 0.6245746 ,\n       0.6570751 , 0.65697473, 0.66824764, 0.6500805 , 0.6860145 ,\n       0.7375461 , 0.7246004 , 0.6891976 , 0.6008763 , 0.47368106,\n       0.4906716 , 0.53379005, 0.5392152 , 0.55555177, 0.61825764,\n       0.61262876, 0.5907667 , 0.56946963, 0.56695455, 0.58794445,\n       0.63173074, 0.56814486, 0.5915515 , 0.62807685, 0.5861584 ,\n       0.55543524, 0.5813181 , 0.54393613, 0.52852637, 0.5011299 ,\n       0.61142975, 0.6082914 , 0.603574  , 0.68250734, 0.70205265,\n       0.7119755 , 0.68619716, 0.70382696, 0.6877239 , 0.67729765,\n       0.63382965, 0.5759701 , 0.6014666 , 0.5416276 , 0.48160294,\n       0.4484571 ], dtype=float32)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:18:56.202408Z",
     "end_time": "2023-11-07T11:18:56.205734Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['font.family']='serif'\n",
    "plt.figure(figsize=(15,6),dpi=300)\n",
    "plt.title('1 Feature Stock Price')\n",
    "plt.plot(range(len(real_y_1)),real_y_1,color='blue',label='Real')\n",
    "plt.plot(range(len(list1)),list1,label='Train Predicted')\n",
    "plt.plot(range(len(real_y_1)+1,len(real_y_1)+len(list2)+1),list2,label='FCN Test Predicted')\n",
    "plt.plot(range(len(real_y_1)+1,len(real_y_1)+len(list2)+1),real_y_2,label='FCN Test Real')\n",
    "# plt.plot(range(len(Y_train_p)+1,len(Y_train_p)+len(Yvalidation)+1),Yvalidation)\n",
    "# plt.plot(validation.index,pd.DataFrame(LSTM_pred),color='red',label='LSTM Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.axvline(len(real_y_1),color='black')\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.savefig('./result/1 Feature Prediction.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3007.5847],\n       [3004.827 ],\n       [3039.9495],\n       [3047.6929],\n       [3048.3567],\n       [3089.3564],\n       [3185.1445]], dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction\n",
    "pred_data=torch.FloatTensor(Price_data[-time_window:].reshape(1,time_window))\n",
    "pre1=fc_model(pred_data)[0].reshape(-1,1)\n",
    "result=scaler1.inverse_transform(pre1.detach().numpy())\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T11:25:42.862925Z",
     "end_time": "2023-11-07T11:25:42.872930Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
